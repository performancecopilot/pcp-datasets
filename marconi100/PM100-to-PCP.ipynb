{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03cdaef2-233a-4c40-9915-bdf80d2d24bf",
   "metadata": {},
   "source": [
    "#  Convert PM100 dataset into Performance Co-Pilot archive format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048117b-adaa-42fc-8d9a-67e01fab61aa",
   "metadata": {},
   "source": [
    "### https://doi.org/10.1145/3624062.3624263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import shutil\n",
    "import cpmapi\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pcp import pmapi, pmi\n",
    "from cpmapi import (\n",
    "    PM_SEM_DISCRETE, PM_SEM_INSTANT, PM_SEM_COUNTER,\n",
    "    PM_SPACE_KBYTE, PM_SPACE_BYTE, PM_TIME_SEC, PM_TIME_USEC, PM_TIME_MSEC,\n",
    "    PM_TYPE_FLOAT, PM_TYPE_U32, PM_TYPE_U64, PM_TYPE_STRING, PM_TYPE_DOUBLE,\n",
    "    PM_ID_NULL, PM_IN_NULL, PM_INDOM_NULL)\n",
    "from cpmi import (PMI_ERR_DUPMETRICNAME, PMI_ERR_DUPINSTNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a942fd5c-bacc-484e-8cec-c7f4fa1802bf",
   "metadata": {},
   "source": [
    "Helper for analysing time spent loading and transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import process_time, perf_counter\n",
    "\n",
    "def start_timer():\n",
    "    t0 = process_time()\n",
    "    c0 = perf_counter()\n",
    "    return (t0, c0)\n",
    "\n",
    "def stop_timer(t0, c0):\n",
    "    t1 = process_time() - t0\n",
    "    c1 = perf_counter() - c0\n",
    "    return 'Completed in %.5f seconds CPU time, %.5f elapsed time' % (t1, c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf66ae6-0547-4e04-914c-62684f08aef5",
   "metadata": {},
   "source": [
    "Helper for discarding some PM-100 information (e.g. weather details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45876d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_metric(plugin, name):\n",
    "    #print('Ignoring', plugin, 'metric', name)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab006f7-0278-46e5-afa3-88bd82b641f6",
   "metadata": {},
   "source": [
    "### Functions providing PCP metric metadata for IPMI metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb83cbc-a3bd-42db-9cc5-340a628529ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipmi_ambient(log): return {\n",
    "    'name': 'roomtemp.ipmi.ambient', 'pmid': log.pmiID(60, 1, 3),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "    \n",
    "def ipmi_total_power(log): return {\n",
    "    'name': 'power.ipmi.total', 'pmid': log.pmiID(34, 1, 0),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e82cc-6eda-4ea9-913d-dd1472ddbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ipmi_metrics = {\n",
    "    'ambient': ipmi_ambient,\n",
    "    'total_power': ipmi_total_power,\n",
    "}\n",
    "\n",
    "def file_ipmi_metric(log, filename):\n",
    "    try:\n",
    "        ipmi_metric = file_ipmi_metrics[filename]\n",
    "        return ipmi_metric(log)\n",
    "    except:\n",
    "        pass # ignore misc environmental readings\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95971078-8ab6-4f52-ba8d-49c9ddd37504",
   "metadata": {},
   "source": [
    "### Functions providing PCP metric metadata for all GPU metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c231f3-1b31-41e2-be2f-2f99bc368f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_gpu_metric(log, metricname, instid, instname): return {\n",
    "    'name': 'gpu.' + metricname, 'pmid': PM_ID_NULL,\n",
    "    'indom': log.pmiInDom(120, 0), 'instid': instid, 'instname': instname,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "\n",
    "def file_gpu_metric(log, metricname):\n",
    "    # match on input like: \"Gpu2_xid_errors\"\n",
    "    # PCP metric becomes: gpu.xid_errors[GPU2]\n",
    "    scan = re.search(r'Gpu([0-9].*?)_(.*)', metricname)\n",
    "    if not scan:\n",
    "        return None\n",
    "    gpu_id = int(scan.group(1))\n",
    "    gpu_name = 'GPU' + scan.group(1)\n",
    "    metric_name = 'gpu.' + scan.group(2)\n",
    "    return generic_gpu_metric(log, metric_name, gpu_id, gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabff9d4-dad4-42fb-b008-729a2bd5383a",
   "metadata": {},
   "source": [
    "### Functions providing PCP metric metadata for all kernel metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671ef46-d826-4d49-8213-f63b1c4d6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinv_ncpu(log): return {\n",
    "    'name': 'hinv.ncpu', 'pmid': log.pmiID(60, 0, 32),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U32, 'sem': PM_SEM_DISCRETE,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "\n",
    "def kernel_all_load(log, instid, instname): return {\n",
    "    'name': 'kernel.all.load', 'pmid': log.pmiID(60, 2, 0),\n",
    "    'indom': log.pmiInDom(60, 2), 'instid': instid, 'instname': instname,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "def kernel_all_load1(log): return kernel_all_load(log, 1, '1 minute')\n",
    "def kernel_all_load5(log): return kernel_all_load(log, 5, '5 minute')\n",
    "def kernel_all_load15(log): return kernel_all_load(log, 15, '15 minute')\n",
    "\n",
    "def mem_util_bufmem(log): return {\n",
    "    'name': 'mem.util.bufmem', 'pmid': log.pmiID(60, 1, 4),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}\n",
    "\n",
    "def mem_util_cached(log): return {\n",
    "    'name': 'mem.util.cached', 'pmid': log.pmiID(60, 1, 5),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}\n",
    "\n",
    "def mem_util_free(log): return {\n",
    "    'name': 'mem.util.free', 'pmid': log.pmiID(60, 1, 2),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}\n",
    "\n",
    "def mem_util_shared(log): return {\n",
    "    'name': 'mem.util.shared', 'pmid': log.pmiID(60, 1, 3),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}\n",
    "\n",
    "def mem_physmem(log): return {\n",
    "    'name': 'mem.physmem', 'pmid': log.pmiID(60, 1, 0),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_DISCRETE,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}\n",
    "\n",
    "def kernel_all_nprocs(log): return {\n",
    "    'name': 'kernel.all.nprocs', 'pmid': log.pmiID(60, 2, 3),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "\n",
    "def kernel_all_running(log): return {\n",
    "    'name': 'kernel.all.running', 'pmid': log.pmiID(60, 0, 15),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "\n",
    "def swap_length(log): return {\n",
    "    'name': 'swap.length', 'pmid': log.pmiID(60, 1, 6),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_BYTE, 0, 0)\n",
    "}\n",
    "    \n",
    "def swap_free(log): return {\n",
    "    'name': 'swap.free', 'pmid': log.pmiID(60, 1, 8),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_BYTE, 0, 0)\n",
    "}\n",
    "    \n",
    "def kernel_uname_sysname(log): return {\n",
    "    'name': 'kernel.uname.sysname', 'pmid': log.pmiID(60, 12, 2),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_STRING, 'sem': PM_SEM_DISCRETE,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "    \n",
    "def kernel_uname_release(log): return {\n",
    "    'name': 'kernel.uname.release', 'pmid': log.pmiID(60, 12, 0),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_STRING, 'sem': PM_SEM_DISCRETE,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "    \n",
    "def kernel_uname_machine(log): return {\n",
    "    'name': 'kernel.uname.machine', 'pmid': log.pmiID(60, 12, 3),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_STRING, 'sem': PM_SEM_DISCRETE,\n",
    "    'units': log.pmiUnits(0, 0, 0, 0, 0, 0)\n",
    "}\n",
    "    \n",
    "def kernel_all_boottime(log): return {\n",
    "    'name': 'kernel.all.boottime', 'pmid': log.pmiID(60, 0, 17),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_U64, 'sem': PM_SEM_DISCRETE,\n",
    "    'units': log.pmiUnits(0, 1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "    \n",
    "def kernel_all_idletime(log): return {\n",
    "    'name': 'kernel.all.idletime', 'pmid': log.pmiID(60, 26, 1),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_DOUBLE, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "\n",
    "def hinv_all_cpu_clock(log): return {\n",
    "    'name': 'hinv.all.cpu.clock', 'pmid': PM_ID_NULL,\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_DISCRETE,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_USEC, 0)\n",
    "}\n",
    "    \n",
    "def kernel_all_cpu_user(log): return {\n",
    "    'name': 'kernel.all.cpu.user', 'pmid': log.pmiID(60, 0, 20),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "\n",
    "def kernel_all_cpu_wait_total(log): return {\n",
    "    'name': 'kernel.all.cpu.wait.total', 'pmid': log.pmiID(60, 0, 35),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "    \n",
    "def kernel_all_cpu_steal(log): return {\n",
    "    'name': 'kernel.all.cpu.steal', 'pmid': log.pmiID(60, 0, 55),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "    \n",
    "def kernel_all_cpu_nice(log): return {\n",
    "    'name': 'kernel.all.cpu.nice', 'pmid': log.pmiID(60, 0, 21),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "    \n",
    "def kernel_all_cpu_idle(log): return {\n",
    "    'name': 'kernel.all.cpu.idle', 'pmid': log.pmiID(60, 0, 23),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "    \n",
    "def kernel_all_cpu_sys(log): return {\n",
    "    'name': 'kernel.all.cpu.sys', 'pmid': log.pmiID(60, 0, 22),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, -1, 0, 0, PM_TIME_SEC, 0)\n",
    "}\n",
    "    \n",
    "def network_all_out_packets(log): return {\n",
    "    'name': 'network.all.out.packets', 'pmid': log.pmiID(60, 90, 5),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, -1, 0, 0, 1)\n",
    "}\n",
    "\n",
    "def network_all_in_packets(log): return {\n",
    "    'name': 'network.all.in.packets', 'pmid': log.pmiID(60, 90, 1),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(0, 0, -1, 0, 0, 1)\n",
    "}\n",
    "    \n",
    "def network_all_out_bytes(log): return {\n",
    "    'name': 'network.all.out.bytes', 'pmid': log.pmiID(60, 90, 4),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(-1, 0, 0, PM_SPACE_BYTE, 0, 0)\n",
    "}\n",
    "    \n",
    "def network_all_in_bytes(log): return {\n",
    "    'name': 'network.all.in.bytes', 'pmid': log.pmiID(60, 90, 0),\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(-1, 0, 0, PM_SPACE_BYTE, 0, 0)\n",
    "}\n",
    "\n",
    "def filesys_all_free(log): return {\n",
    "    'name': 'filesys.all.free', 'pmid': PM_ID_NULL,\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}\n",
    "    \n",
    "def filesys_all_capacity(log): return {\n",
    "    'name': 'filesys.all.capacity', 'pmid': PM_ID_NULL,\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}\n",
    "    \n",
    "def filesys_all_maxused(log): return {\n",
    "    'name': 'filesys.all.maxused', 'pmid': PM_ID_NULL,\n",
    "    'indom': None, 'instid': None, 'instname': None,\n",
    "    'type': PM_TYPE_FLOAT, 'sem': PM_SEM_INSTANT,\n",
    "    'units': log.pmiUnits(1, 0, 0, PM_SPACE_KBYTE, 0, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bad715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping individual PM100 file names to specific PCP metrics\n",
    "file_kernel_metrics = {\n",
    "    'cpu_num': hinv_ncpu,\n",
    "    'mem_buffers': mem_util_bufmem,\n",
    "    'mem_cached': mem_util_cached,\n",
    "    'mem_free': mem_util_free,\n",
    "    'mem_shared': mem_util_shared,\n",
    "    'mem_total': mem_physmem,\n",
    "    'proc_total': kernel_all_nprocs,\n",
    "    'proc_run': kernel_all_running,\n",
    "    'swap_total': swap_length,\n",
    "    'swap_free': swap_free,\n",
    "    'os_name': kernel_uname_sysname,\n",
    "    'os_release': kernel_uname_release,\n",
    "    'machine_type': kernel_uname_machine,\n",
    "    'boottime': kernel_all_boottime,\n",
    "    'cpu_aidle': kernel_all_idletime,\n",
    "    'cpu_speed': hinv_all_cpu_clock,\n",
    "    'cpu_user': kernel_all_cpu_user,\n",
    "    'cpu_wio': kernel_all_cpu_wait_total,\n",
    "    'cpu_steal': kernel_all_cpu_steal,\n",
    "    'cpu_nice': kernel_all_cpu_nice,\n",
    "    'cpu_idle': kernel_all_cpu_idle,\n",
    "    'cpu_system': kernel_all_cpu_sys,\n",
    "    'load_one': kernel_all_load1,\n",
    "    'load_five': kernel_all_load5,\n",
    "    'load_fifteen': kernel_all_load15,\n",
    "    'pkts_out': network_all_out_packets,\n",
    "    'pkts_in': network_all_in_packets,\n",
    "    'bytes_out': network_all_out_bytes,\n",
    "    'bytes_in': network_all_in_bytes,\n",
    "    'disk_free': filesys_all_free,\n",
    "    'disk_total': filesys_all_capacity,\n",
    "    'part_max_used': filesys_all_maxused,\n",
    "    'gexec': None, # \"scalable cluster remote execution system\"\n",
    "}\n",
    "\n",
    "def file_kernel_metric(log, filename):\n",
    "    try:\n",
    "        kernel_metric = file_kernel_metrics[filename]\n",
    "        if not kernel_metric:\n",
    "            raise TypeError(filename)\n",
    "        return kernel_metric(log)\n",
    "    except:\n",
    "        print('Kernel metric missing:', filename)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73384238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_mapping(log, file):\n",
    "    result = re.search(r'/plugin=(.*?)/metric=(.*?)/', file)\n",
    "    plugin, metric = result.group(1, 2)\n",
    "    #print(plugin, metric)\n",
    "\n",
    "    if plugin == 'ganglia_pub':\n",
    "        if metric[:3] == 'Gpu':\n",
    "            return file_gpu_metric(log, metric)\n",
    "        return file_kernel_metric(log, metric)\n",
    "    elif plugin == 'ipmi_pub':\n",
    "        return file_ipmi_metric(log, metric)\n",
    "\n",
    "    # ignore all other recorded subsystems\n",
    "    elif plugin in ['weather_pub', 'nagios_pub']:  # misc monitoring\n",
    "        return ignore_metric(plugin, metric)\n",
    "    elif plugin in ['job_table', 'slurm_pub']:  # HPC job scheduler\n",
    "        return ignore_metric(plugin, metric)\n",
    "    elif plugin in ['logics_pub', 'vertiv_pub', 'schneider_pub']:\n",
    "        return ignore_metric(plugin, metric)\n",
    "\n",
    "    print('Plugin handler missing:', plugin)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b6ad6-f977-42bb-8323-4d9ecad658c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(df, node, column, datestring):\n",
    "    node_df = df.loc[df['node'] == node]  # just this node\n",
    "    node_df.set_index('timestamp', inplace=True)\n",
    "    try:  # there may be no data on this day (e.g. GPU metrics)\n",
    "        node_df = node_df.loc[datestring]  # just this day\n",
    "    except KeyError:\n",
    "        return None\n",
    "    node_df = node_df.rename({'value': column}, axis=1)\n",
    "    node_df = node_df.drop('node', axis=1)\n",
    "    return node_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacdffc6-1db8-4803-9832-ceef4cdea9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_dataframes(host='marconi100', year=2022, month=9, day=1, nodes=None):\n",
    "    \"\"\"\n",
    "    Reads PM100 dataset for a single day.  Returns a tuple with two dictionaries:\n",
    "    1. dataframes with metric columns indexed by timestamp, for each node\n",
    "    2. mapping dataframe column names back to PCP metric metadata\n",
    "    \"\"\"\n",
    "    node_dfs = {}\n",
    "    column_map = {}\n",
    "    datestring = '%d-%02d-%02d' % (year, month, day)\n",
    "\n",
    "    files = glob.glob('year_month=*/plugin=*/metric=*/*.parquet')\n",
    "    base = pmi.pmiLogImport(host) # for static functions\n",
    "\n",
    "    for file in files:\n",
    "        pcp_metric = get_file_mapping(base, file)\n",
    "        if not pcp_metric:\n",
    "            continue\n",
    "    \n",
    "        tt, cc = start_timer()    \n",
    "        df = pd.read_parquet(file)\n",
    "        ss = stop_timer(tt, cc)\n",
    "    \n",
    "        if 'node' not in df.columns:\n",
    "            print('No node column in', file)\n",
    "            continue\n",
    "        print('*** Loaded', file)\n",
    "        print(ss)\n",
    "    \n",
    "        if not nodes: # no subset; all nodes\n",
    "            nodes = sorted(df.node.unique())\n",
    "\n",
    "        for node in nodes:    \n",
    "            column = pcp_metric['name']   # regular PCP name\n",
    "            if pcp_metric['instname']:\n",
    "                column += '[' + pcp_metric['instname'] + ']'\n",
    "            column_map[column] = pcp_metric\n",
    "    \n",
    "            #tt, cc = start_timer()    \n",
    "    \n",
    "            nodedf = get_node(df, node, column, datestring)\n",
    "            if nodedf is None:   # e.g. missing GPU metrics\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                ndf = node_dfs[node]\n",
    "                #print('Merging node', node, 'with', len(nodedf), 'rows and', len(nodedf.columns), 'columns.')\n",
    "                ndf = ndf.merge(nodedf, how='outer', left_index=True, right_index=True)\n",
    "            except KeyError:\n",
    "                ndf = nodedf\n",
    "            node_dfs[node] = ndf\n",
    "    \n",
    "            #ss = stop_timer(tt, cc)\n",
    "            #print('Completed node', node, 'from file', file, 'with', len(ndf), 'rows and', len(ndf.columns), 'columns.')\n",
    "            #print(ss)\n",
    "\n",
    "    del base # finished with temporary log (hack for using static functions)\n",
    "\n",
    "    return (node_dfs, column_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95f837-0553-4294-8e55-c4f7f9a36961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_column_metadata(log, column, column_map):\n",
    "    #print(column)\n",
    "    metric = column_map[column]\n",
    "    name = metric['name']\n",
    "    if name in combined:\n",
    "        return\n",
    "    indom = metric['indom']\n",
    "    if not indom:\n",
    "        indom = PM_INDOM_NULL\n",
    "\n",
    "    #print('AddMetric:', name)\n",
    "    try:\n",
    "        log.pmiAddMetric(name, metric['pmid'], metric['type'],\n",
    "                     indom, metric['sem'], metric['units'])\n",
    "    except pmi.pmiErr as error:\n",
    "        if indom == PM_INDOM_NULL and error.code == PMI_ERR_DUPMETRICNAME:\n",
    "            pass  # duplicates inserts\n",
    "    if indom != PM_INDOM_NULL:\n",
    "        #print('AddInstance:', metric['instname'])\n",
    "        try:\n",
    "            log.pmiAddInstance(indom, metric['instname'], metric['instid'])\n",
    "        except pmi.pmiErr as error:\n",
    "            if error.code == PMI_ERR_DUPINSTNAME:\n",
    "                pass  # duplicate inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0c126-2cb5-44a1-9fa3-648f6574e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_node_dataframes(archive, logpath, host, node_dfs, column_map, combined=[]):\n",
    "    \"\"\"\n",
    "    Write out PCP archive for a single node and single day of data.\n",
    "    \"\"\"\n",
    "    epoch = datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)\n",
    "    nlogs = 0\n",
    "\n",
    "    for node, node_df in node_dfs.items():\n",
    "        nodename = '%s_node%s' % (host, node.zfill(3))\n",
    "        hostname = '%s.cineca.it' % (nodename)\n",
    "        filename = '%s/%s/%s' % (logpath, nodename, archive)\n",
    "    \n",
    "        dirname = os.path.dirname(filename)\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        print('Host:', hostname)\n",
    "        print('File:', filename)\n",
    "    \n",
    "        log = pmi.pmiLogImport(filename)\n",
    "        log.pmiSetHostname(hostname)\n",
    "        log.pmiSetTimezone(timezone)\n",
    "    \n",
    "        # add metric/indom metadata to the archive\n",
    "        for column in node_df.columns:\n",
    "            #print(column)\n",
    "            if column in combined:\n",
    "                continue\n",
    "            put_column_metadata(log, column, column_map)\n",
    "    \n",
    "        # add values from each metric to the archive\n",
    "        for row in node_df.itertuples(index=True, name='sample'):\n",
    "            #print(len(row), row)\n",
    "            seconds = int((row[0] - epoch).total_seconds())\n",
    "            count = 0\n",
    "            for c, column in enumerate(node_df.columns):\n",
    "                if column in combined:\n",
    "                    continue\n",
    "                value = row[c+1]\n",
    "                if not isinstance(value, str):\n",
    "                    if math.isnan(value):\n",
    "                        continue\n",
    "                    value = str(value).rstrip('.0')\n",
    "                metric = column_map[column]\n",
    "                instname = metric['instname'] or ''\n",
    "                log.pmiPutValue(metric['name'], instname, value)\n",
    "                count += 1\n",
    "    \n",
    "            log.pmiWrite(seconds, 0)\n",
    "            print('Wrote:', count, 'metric values at offset', seconds, row[0])\n",
    "\n",
    "        nlogs += 1\n",
    "        del log\n",
    "\n",
    "    return nlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858534c4-ed4e-4008-91fe-3f50dc47640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_agg_dataframes(archive, logpath, host, node_dfs, column_map, combined):\n",
    "    \"\"\"\n",
    "    Write out PCP archive for aggregated metrics for a single day of data.\n",
    "    \"\"\"\n",
    "    epoch = datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)\n",
    "\n",
    "    hostname = '%s.cineca.it' % (host)\n",
    "    filename = '%s/%s/%s' % (logpath, hostname, archive)\n",
    "    \n",
    "    print('Host:', hostname)\n",
    "    print('File:', filename)\n",
    "    \n",
    "    log = pmi.pmiLogImport(filename)\n",
    "    log.pmiSetHostname(hostname)\n",
    "    log.pmiSetTimezone(timezone)\n",
    "\n",
    "    # add combined metric/indom metadata to the archive\n",
    "    for column in combined:\n",
    "        put_column_metadata(log, column, column_map)\n",
    "\n",
    "        first = True\n",
    "        for nodedf in node_dfs:\n",
    "            if first:\n",
    "                first = False\n",
    "                summed = nodedf\n",
    "                continue\n",
    "            summed.set_index(column).add(node.set_index(column), fill_value=0).reset_index()\n",
    "\n",
    "        combined_df = summed  # merge dataframes if more than one metric combined\n",
    "\n",
    "    count = 0\n",
    "    for row in summed.itertuples(index=True, name='sample'):\n",
    "        timestamp = row[0]\n",
    "        seconds = int((timestamp - epoch).total_seconds())\n",
    "        for column in combined:\n",
    "            metric = column_map[column]\n",
    "            instname = metric['instname'] or ''\n",
    "            print(seconds, column, combined[column])\n",
    "            log.pmiPutValue(metric['name'], instname, str(combined[column]))\n",
    "            count += 1\n",
    "        log.pmiWrite(seconds, 0)\n",
    "\n",
    "    print('Wrote:', count, 'accumulated metrics')\n",
    "    del log\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13e92b-eee7-444c-850c-33fea33524a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [(2022, 9, 1)] # - , (2022, 9, 2)]\n",
    "host = 'marconi100'\n",
    "logpath = 'archives'\n",
    "timezone = 'UTC' #'CET'?\n",
    "combined = {'power.ipmi.total': 0}  # metric values accumulated across all nodes\n",
    "nodes = [str(num) for num in list(range(0, 2+1))] # - 'None' for all nodes, time consuming\n",
    "\n",
    "#if os.path.exists(logpath) and os.path.isdir(logpath):\n",
    "#    shutil.rmtree(logpath)\n",
    "\n",
    "for (year, month, day) in days:\n",
    "    archive = '%4d%02d%02d' % (year, month, day)\n",
    "    node_dataframes, column_mapping = get_node_dataframes(host, year, month, day, nodes)\n",
    "    logs = put_node_dataframes(archive, logpath, host, node_dataframes, column_mapping, combined)\n",
    "    logs += put_agg_dataframes(archive, logpath, host, node_dataframes, column_mapping, combined)\n",
    "    print('=== Wrote %d archives for %d-%d-%d' % (logs, day, month, year))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
